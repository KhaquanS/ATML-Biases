{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kxPv4Njtoxy"
      },
      "outputs": [],
      "source": [
        "!pip install timm clip accelerate deeplake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LJ4w6-Vxt99T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hCu_jdLAu7sm"
      },
      "outputs": [],
      "source": [
        "TRAIN_TFMS = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandAugment(),\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "TEST_TFMS = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvBxKK9CuRVK",
        "outputId": "9cd13ca2-93e1-452a-ba09-da3272786d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz to drive/MyDrive/ATML/PA1/task4/imagenette2-320.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 341663724/341663724 [00:12<00:00, 28166444.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting drive/MyDrive/ATML/PA1/task4/imagenette2-320.tgz to drive/MyDrive/ATML/PA1/task4\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.Imagenette(root=path, split='train', size='320px', transform=TRAIN_TFMS, download=True)\n",
        "testset = torchvision.datasets.Imagenette(root=path, split='val', size='320px', transform=TEST_TFMS, download=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oalVV51PvsrW"
      },
      "outputs": [],
      "source": [
        "class_map = {\n",
        "    'n03028079': 'church',\n",
        "    'n01440764': 'tench',\n",
        "    'n03000684': 'chain saw',\n",
        "    'n03425413': 'gas pump',\n",
        "    'n02979186': 'cassette player',\n",
        "    'n02102040': 'English springer',\n",
        "    'n03417042': 'garbage truck',\n",
        "    'n03394916': 'French horn',\n",
        "    'n03888257': 'parachute',\n",
        "    'n03445777': 'golf ball'\n",
        "}\n",
        "\n",
        "dataset_path = \"drive/MyDrive/ATML/PA1/task4/imagenette2-320/val\"\n",
        "\n",
        "for folder in os.listdir(dataset_path):\n",
        "    os.rename(dataset_path + '/' + folder, dataset_path + '/' + class_map[folder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZGcl5Qf0EiZ",
        "outputId": "7156f6c1-4e25-43a8-c27f-481039d7f770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n",
            "Epochs: 100% 2/2 [03:53<00:00, 116.86s/it]\n",
            "\n",
            "============ True Eval Acc: 95.2732%  ============\n",
            "============ True Eval Loss: 0.2203  ============\n",
            "\n",
            "============ Eval Acc on Color dataset: 91.4062%  ============\n",
            "============ Eval Loss on Color dataset: 0.4232  ============\n",
            "\n",
            "Color bias for Vit_small_patch16_224: 95.94%\n"
          ]
        }
      ],
      "source": [
        "!python3 drive/MyDrive/ATML/PA1/task4/custom_infer_vit.py --model_name 'vit_small_16' --out_dir 'drive/MyDrive/ATML/PA1/task4' --train_path 'drive/MyDrive/ATML/PA1/task4/imagenette2-320/train' --val_path 'drive/MyDrive/ATML/PA1/task4/imagenette2-320/val' --bias_eval 'Color' --epochs 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`. Output is equivalent up to float precision.\n",
            "  warnings.warn(\n",
            "\n",
            "Epochs: 100% 2/2 [03:53<00:00, 116.54s/it]\n",
            "\n",
            "============ True Eval Acc: 95.2732%  ============\n",
            "============ True Eval Loss: 0.2203  ============\n",
            "\n",
            "============ Eval Acc on Shape dataset: 48.1932%  ============\n",
            "============ Eval Loss on Shape dataset: 4.8668  ============\n",
            "\n",
            "Shape bias for Vit_small_patch16_224: 50.58%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 drive/MyDrive/ATML/PA1/task4/custom_infer_vit.py --model_name 'vit_small_16' --out_dir 'drive/MyDrive/ATML/PA1/task4' --train_path 'drive/MyDrive/ATML/PA1/task4/imagenette2-320/train' --val_path 'drive/MyDrive/ATML/PA1/task4/imagenette2-320/val' --bias_eval 'Shape' --epochs 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hjz78nT8lor",
        "outputId": "04aceb5a-8b5c-4ab6-ecee-89d9847105c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n",
            "Epochs: 100% 2/2 [03:55<00:00, 117.77s/it]\n",
            "\n",
            "============ True Eval Acc: 95.2732%  ============\n",
            "============ True Eval Loss: 0.2203  ============\n",
            "\n",
            "============ Eval Acc on Texture dataset: 46.1328%  ============\n",
            "============ Eval Loss on Texture dataset: 2.7655  ============\n",
            "\n",
            "Texture bias for Vit_small_patch16_224: 48.42%\n"
          ]
        }
      ],
      "source": [
        "!python3 drive/MyDrive/ATML/PA1/task4/custom_infer_vit.py --model_name 'vit_small_16' --out_dir 'drive/MyDrive/ATML/PA1/task4' --train_path 'drive/MyDrive/ATML/PA1/task4/imagenette2-320/train' --val_path 'drive/MyDrive/ATML/PA1/task4/imagenette2-320/val' --bias_eval 'Texture' --epochs 2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
