{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sw7EEotxEM7"
      },
      "source": [
        "## Task 5 - Inductive Biases of Models: Locality Biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CwpssKGr4tz"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KtNPu0rDsUEp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Gw9sH7n2sj6k"
      },
      "outputs": [],
      "source": [
        "TRAIN_TFMS = transforms.Compose([\n",
        "    transforms.RandAugment(),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "TEST_TFMS = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx-og2yjuXCs"
      },
      "source": [
        "### Evaluating for Scrambled Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`. Output is equivalent up to float precision.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`. Output is equivalent up to float precision.\n",
            "  warnings.warn(\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training: [1563/1563] Loss: 1.2724 Acc: 0.7342\n",
            "Evaluation: [313/313] Loss: 0.2022 Acc: 0.9384\n",
            "============ Epoch 1 --> Train Acc: 0.7342 || Test Acc: 0.9384 || Time: 226.71 s ============\n",
            "\n",
            "Training: [1563/1563] Loss: 0.2878 Acc: 0.9060\n",
            "Evaluation: [313/313] Loss: 0.1528 Acc: 0.9518\n",
            "============ Epoch 2 --> Train Acc: 0.9060 || Test Acc: 0.9518 || Time: 237.67 s ============\n",
            "\n",
            "Epochs: 100% 2/2 [07:44<00:00, 232.19s/it]\n",
            "Evaluation: [313/313] Loss: 3.0567 Acc: 0.2121\n",
            "\n",
            "====================== Normal Accuracy: 95.178% || Scrambled Image Accuracy: 46.348% ======================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3 drive/MyDrive/ATML/PA1/task5/scrambled_images.py --model_name 'vit_small_16' --out_dir 'drive/MyDrive/ATML/PA1/task5' --dataset 'CIFAR-10' --patch_size 56 --epochs 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqfuGHequDzH"
      },
      "source": [
        "### Evaluating for Noise Injection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AdM8rPRCsRkV"
      },
      "outputs": [],
      "source": [
        "# Custom transform which injects local noise\n",
        "class AddNoiseToPatch:\n",
        "    def __init__(self, noise_level=0.1, patch_coords=(0, 0, 50, 50)):\n",
        "        self.noise_level = noise_level\n",
        "        self.patch_coords = patch_coords  # (x1, y1, x2, y2)\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # Convert to numpy array\n",
        "        img_np = np.array(img)\n",
        "\n",
        "        # Extract patch coordinates\n",
        "        x1, y1, x2, y2 = self.patch_coords\n",
        "\n",
        "        # Generate random noise\n",
        "        noise = np.random.normal(0, self.noise_level, img_np[y1:y2, x1:x2].shape).astype(np.uint8)\n",
        "\n",
        "        # Add noise to the patch\n",
        "        img_np[y1:y2, x1:x2] = np.clip(img_np[y1:y2, x1:x2] + noise, 0, 255)\n",
        "\n",
        "        # Convert back to PIL Image\n",
        "        return Image.fromarray(img_np)\n",
        "\n",
        "def get_noised_data(noise_size, root):\n",
        "\n",
        "    NOISE_TEST_TFMS = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.CenterCrop(224),\n",
        "        AddNoiseToPatch(noise_level=25, patch_coords=(50, 50, 50+noise_size, 50+noise_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root, train=True, download=True, transform=TRAIN_TFMS\n",
        "    )\n",
        "\n",
        "    normal_testset = torchvision.datasets.CIFAR10(\n",
        "        root, train=False, download=True, transform=TEST_TFMS\n",
        "    )\n",
        "\n",
        "    noised_testset = torchvision.datasets.CIFAR10(\n",
        "        root, train=False, download=True, transform=NOISE_TEST_TFMS\n",
        "    )\n",
        "\n",
        "    return trainset, normal_testset, noised_testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jL4f5n1JsoFS"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def eval_step(model, dataloader, criterion, device):\n",
        "    '''Evaluate the model'''\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss = 0.0\n",
        "    eval_acc = 0.0\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        logits = model(X)\n",
        "        loss = criterion(logits, y)\n",
        "        eval_loss += loss.item()\n",
        "\n",
        "        y_pred = torch.argmax(logits.detach(), dim=1)\n",
        "        eval_acc += (y_pred == y).sum().item() / len(y)\n",
        "\n",
        "        # Print dynamic progress on the same line using \\r\n",
        "        print(f'\\rEvaluation: [{i+1}/{len(dataloader)}] '\n",
        "              f'Loss: {eval_loss / (i + 1):.4f} '\n",
        "              f'Acc: {eval_acc / (i + 1):.4f}', end='')\n",
        "\n",
        "    eval_loss = eval_loss / len(dataloader)\n",
        "    eval_acc = eval_acc / len(dataloader)\n",
        "\n",
        "    # Move to the next line after the loop is done\n",
        "    print()\n",
        "\n",
        "    return eval_loss, eval_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K2tGYHHlsxNr"
      },
      "outputs": [],
      "source": [
        "saved_path = 'drive/MyDrive/ATML/PA1/model/cifar10_final.pth'\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = timm.create_model('vit_small_patch16_224', pretrained=False)\n",
        "model.load_state_dict(torch.load(saved_path, weights_only=True))\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6eFHTbnszBW",
        "outputId": "48a5965b-5e11-4217-9112-e2b6214c0bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "def get_dataloader(dataset: Dataset,\n",
        "                   batch_size: int,\n",
        "                   is_train: bool,\n",
        "                   num_workers: int = 1):\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size,\n",
        "                        shuffle=is_train, num_workers=num_workers)\n",
        "    return loader\n",
        "\n",
        "_, normal_testset, noised_testset = get_noised_data(noise_size=100, root='drive/MyDrive/ATML/PA1')\n",
        "normal_dl = get_dataloader(normal_testset, batch_size=64, is_train=False)\n",
        "noise_dl = get_dataloader(noised_testset, batch_size=64, is_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB9tzvkos25_",
        "outputId": "4c26be3b-8cce-4d55-ef9c-d8b9d4ebafb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation: [157/157] Loss: 0.1270 Acc: 0.9592\n",
            "Evaluation: [157/157] Loss: 0.2346 Acc: 0.9293\n",
            "\n",
            "====================== Normal Accuracy: 95.920% || Noise Injected Accuracy: 92.934% ======================\n"
          ]
        }
      ],
      "source": [
        "normal_loss, normal_acc = eval_step(model, normal_dl, criterion, device)\n",
        "noise_loss, noise_acc = eval_step(model, noise_dl, criterion, device)\n",
        "\n",
        "print(f'\\n====================== Normal Accuracy: {normal_acc*100:.3f}% || Noise Injected Accuracy: {noise_acc*100:.3f}% ======================')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoZVpGnZu4jy"
      },
      "source": [
        "### Evaluating Global Style Changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_custom_data(path: str):\n",
        "    dataset = datasets.ImageFolder(path, transform=TEST_TFMS)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "global_style_testset = get_custom_data(\"../input/cifar10/stylized_cifar10\")\n",
        "global_style_dl = get_dataloader(\n",
        "    global_style_testset, batch_size=64, is_train=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation: [157/157] Loss: 0.1533 Acc: 0.9493\n",
            "Evaluation: [8/8] Loss: 1.3926 Acc: 0.5575\n",
            "====================== Normal Accuracy: 94.9343% || Global Style Accuracy: 55.7542% ======================\n"
          ]
        }
      ],
      "source": [
        "normal_loss, normal_acc = eval_step(model, normal_dl, criterion, device)\n",
        "global_style_loss, global_style_acc = eval_step(model, global_style_dl, criterion, device)\n",
        "\n",
        "print(f\"====================== Normal Accuracy: {normal_acc*100:.4f}% || Global Style Accuracy: {global_style_acc*100:.4f}% ======================\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
